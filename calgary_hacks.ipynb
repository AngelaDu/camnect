{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "calgary_hacks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmDbkTlfjmyR",
        "outputId": "74aed8a1-ae3f-455f-d869-5b890fa0b71f"
      },
      "source": [
        "!pip install numpy\r\n",
        "!pip install opencv-python\r\n",
        "!pip install tensorflow\r\n",
        "!pip install tflearn\r\n",
        "!pip install keras\r\n",
        "!pip install spotipy --upgrade\r\n",
        "!pip install play_mood_music"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (53.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp36-none-any.whl size=127301 sha256=54d557e4dfe63ae438c5c9a03c1f00fe771ee19117b9fce41cb34228617f0adf\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Collecting spotipy\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/cd/e7d9a35216ea5bfb9234785f3d8fa7c96d0e33999c2cb72394128f6b4cce/spotipy-2.16.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from spotipy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from spotipy) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->spotipy) (2.10)\n",
            "Installing collected packages: spotipy\n",
            "Successfully installed spotipy-2.16.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement play_mood_music (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for play_mood_music\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG8ZmudAjpJL"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.core import Dense, Dropout, Flatten\r\n",
        "from keras.layers.convolutional import Conv2D\r\n",
        "from keras.layers.pooling import MaxPooling2D\r\n",
        "import os\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "import spotipy\r\n",
        "import random\r\n",
        "from spotipy.oauth2 import SpotifyOAuth\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LhoH87zJrkC"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x23UX8XhnRKG"
      },
      "source": [
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import matplotlib as mpl\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.core import Dense, Dropout, Flatten\r\n",
        "from keras.layers.convolutional import Conv2D\r\n",
        "# from play_mood_music import setup, next_track\r\n",
        "from keras.layers.pooling import MaxPooling2D\r\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agyIWOoNnUrO"
      },
      "source": [
        "\r\n",
        "def authenticate(scope='user-modify-playback-state,user-read-playback-state'):\r\n",
        "    return spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope, redirect_uri=\"https://localhost:8000\"))\r\n",
        "\r\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baTTGWRGnVrb"
      },
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n",
        "mpl.use('TkAgg')\r\n",
        "\r\n",
        "# settings\r\n",
        "RUNNING_AVERAGE_SAMPLES = 5\r\n",
        "LONGTERM_ROLLING_AVERAGE_SAMPLES = 5\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1msnpeMjnWH7"
      },
      "source": [
        "# Query Spotify to get a new track matching the given mood\r\n",
        "\r\n",
        "\r\n",
        "def get_new_track_uri(spotify, mood, playlist_offset=None, track_offset=None, instrumental=False):\r\n",
        "    # query for a playlist with a matching \"mood\"\r\n",
        "\r\n",
        "    if playlist_offset is None:\r\n",
        "        playlist_offset = random.randint(0, 10)\r\n",
        "    if track_offset is None:\r\n",
        "        track_offset = random.randint(0, 20)\r\n",
        "\r\n",
        "    if instrumental:\r\n",
        "        results = spotify.search(q=mood + ' instrumental', type='playlist', limit=1, offset=playlist_offset)\r\n",
        "    else:\r\n",
        "        results = spotify.search(q=mood, type='playlist', limit=1, offset=playlist_offset)\r\n",
        "    if len(results) < 1:\r\n",
        "        return get_new_track_uri(spotify, mood, playlist_offset=0, instrumental=instrumental)\r\n",
        "    playlist_id = results['playlists']['items'][0]['id']\r\n",
        "\r\n",
        "    # query the selected playlist for a random track\r\n",
        "    results = spotify.playlist_items(playlist_id, market=\"CA\", limit=1, offset=track_offset)\r\n",
        "    if len(results) < 1:\r\n",
        "        return get_new_track_uri(spotify, mood, playlist_offset=playlist_offset, track_offset=0)\r\n",
        "    uri = results['items'][0]['track']['uri']\r\n",
        "\r\n",
        "    return uri"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ftfiG2nXRx"
      },
      "source": [
        "# Verify that there is an active device\r\n",
        "def has_active_device(spotify):\r\n",
        "    devices = spotify.devices()\r\n",
        "    for d in devices['devices']:\r\n",
        "        if d['is_active']:\r\n",
        "            return True\r\n",
        "    return False\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLuUCLhhx2aK"
      },
      "source": [
        "# Fade the volume up\r\n",
        "def fade_in(spotify):\r\n",
        "    for i in range(25):\r\n",
        "        spotify.volume(50+(i*2))\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZAHblCux2vl"
      },
      "source": [
        "# Fade the volume down\r\n",
        "def fade_out(spotify):\r\n",
        "    for i in range(25):\r\n",
        "        spotify.volume(100-(i*2))\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxQuBt7lx3BU"
      },
      "source": [
        "# Put a given track next in queue and switch from the current song to it\r\n",
        "# optional fade into new song\r\n",
        "def change_songs(spotify, track_uri):\r\n",
        "    if not has_active_device(spotify):\r\n",
        "        print(\"err: no active device\")\r\n",
        "        quit()\r\n",
        "    spotify.add_to_queue(track_uri)\r\n",
        "    fade_out(spotify)\r\n",
        "    spotify.next_track()\r\n",
        "    fade_in(spotify)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQxQo6mDx3Uy"
      },
      "source": [
        "# Get a song matching the mood and start playing it\r\n",
        "def next_track(spotify, mood, instrumental=False):\r\n",
        "    track_uri = get_new_track_uri(spotify, mood, instrumental=instrumental)\r\n",
        "    change_songs(spotify, track_uri)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8FzUqYBx3y8"
      },
      "source": [
        "# Authenticates and sets volume to 100\r\n",
        "# return authentication object\r\n",
        "def setup(scope=None):\r\n",
        "    if scope is not None:\r\n",
        "        spotify = authenticate(scope)\r\n",
        "    else:\r\n",
        "        spotify = authenticate()\r\n",
        "\r\n",
        "    if not has_active_device(spotify):\r\n",
        "        print(\"err: no active devices\")\r\n",
        "        quit()\r\n",
        "    spotify.volume(100)\r\n",
        "    return spotify"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzmE33thx4DC"
      },
      "source": [
        "# Plot of accuracy and loss\r\n",
        "def plot_model_history(model_history):\r\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\r\n",
        "    # summarize history for accuracy\r\n",
        "    axs[0].plot(range(1, len(model_history.history['accuracy']) + 1), model_history.history['accuracy'])\r\n",
        "    axs[0].plot(range(1, len(model_history.history['val_accuracy']) + 1), model_history.history['val_accuracy'])\r\n",
        "    axs[0].set_title('Model Accuracy')\r\n",
        "    axs[0].set_ylabel('Accuracy')\r\n",
        "    axs[0].set_xlabel('Epoch')\r\n",
        "    axs[0].set_xticks(np.arange(1, len(model_history.history['accuracy']) + 1),\r\n",
        "                      len(model_history.history['accuracy']) / 10)\r\n",
        "    axs[0].legend(['train', 'val'], loc='best')\r\n",
        "    # summarize history for loss\r\n",
        "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\r\n",
        "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\r\n",
        "    axs[1].set_title('Model Loss')\r\n",
        "    axs[1].set_ylabel('Loss')\r\n",
        "    axs[1].set_xlabel('Epoch')\r\n",
        "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), len(model_history.history['loss']) / 10)\r\n",
        "    axs[1].legend(['train', 'val'], loc='best')\r\n",
        "    fig.savefig('plot.png')\r\n",
        "    plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKHF4O3ax4cZ"
      },
      "source": [
        "# Define data generators\r\n",
        "train_dir = 'data/train'\r\n",
        "val_dir = 'data/test'\r\n",
        "\r\n",
        "num_train = 28709\r\n",
        "num_val = 7178\r\n",
        "batch_size = 64\r\n",
        "num_epoch = 50\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "# train_generator = train_datagen.flow_from_directory(\r\n",
        "#    train_dir,\r\n",
        "#    target_size=(48, 48),\r\n",
        "#    batch_size=batch_size,\r\n",
        "#    color_mode=\"grayscale\",\r\n",
        "#    class_mode='categorical')\r\n",
        "\r\n",
        "# validation_generator = val_datagen.flow_from_directory(\r\n",
        "#    val_dir,\r\n",
        "#    target_size=(48, 48),\r\n",
        "#    batch_size=batch_size,\r\n",
        "#    color_mode=\"grayscale\",\r\n",
        "#    class_mode='categorical')\r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mcFgyZEx4uW"
      },
      "source": [
        "# Create the model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\r\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(1024, activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(7, activation='softmax'))\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsCy7Pz7ycmt"
      },
      "source": [
        "# Create the model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\r\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWs2aq5Lyc-R"
      },
      "source": [
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKd1hGTCydSN"
      },
      "source": [
        "model.add(Flatten())\r\n",
        "model.add(Dense(1024, activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVn7I_mIydn1"
      },
      "source": [
        "spotify = setup()  # setup Spotify integration\r\n",
        "model.load_weights('model.h5')\r\n",
        "cv2.ocl.setUseOpenCL(False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bmV2IgFyd9m"
      },
      "source": [
        "# Dictionaries\r\n",
        "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Neutral\", 3: \"Happy\",\r\n",
        "                4: \"Neutral\", 5: \"Sad\", 6: \"Happy\"}\r\n",
        "\r\n",
        "action_dict = {0: \"Calming down user\", 1: \"Skip to next song\", 2: \"No change\", 3: \"Upbeat Environment\",\r\n",
        "               4: \"No change\", 5: \"Calming down user\", 6: \"Upbeat Environment\"}\r\n",
        "\r\n",
        "spotipy_dict = {0: \"Rock\", 1: \"skip\", 2: \"\", 3: \"Upbeat\",\r\n",
        "                4: \"\", 5: \"Piano\", 6: \"Upbeat\"}\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARD8Kvl-yeRa"
      },
      "source": [
        "# Webcam Feed (LIVE)\r\n",
        "cap = cv2.VideoCapture(0)\r\n",
        "rolling_samples = []\r\n",
        "freqs = np.zeros(6, dtype=int)\r\n",
        "longterm_rolling_average = []\r\n",
        "longterm_freqs = np.zeros(6, dtype=int)\r\n",
        "prevmaxmood = None\r\n",
        "maxmood = 4\r\n",
        "sample = 0\r\n",
        "while True:\r\n",
        "  # Find haar cascade to draw bounding box around face and eyes\r\n",
        "    ret, frame = cap.read()\r\n",
        "    frame = cv2.flip(frame, 1)\r\n",
        "    facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\r\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
        "    faces = facecasc.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\r\n",
        "\r\n",
        "    for (x, y, w, h) in faces:\r\n",
        "        cv2.rectangle(frame, (x, y - 50), (x + w, y + h + 10), (255, 0, 0), 2)\r\n",
        "        roi_gray = gray[y:y + h, x:x + w]\r\n",
        "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\r\n",
        "        prediction = model.predict(cropped_img)\r\n",
        "        maxindex = int(np.argmax(prediction))\r\n",
        "\r\n",
        "        # take rolling average\r\n",
        "        if len(rolling_samples) >= RUNNING_AVERAGE_SAMPLES:\r\n",
        "            oldest = rolling_samples.pop(0)\r\n",
        "            freqs[oldest] -= 1\r\n",
        "\r\n",
        "        # map surprised to happy\r\n",
        "        if maxindex == 6:\r\n",
        "            maxindex = 3\r\n",
        "\r\n",
        "        rolling_samples.append(maxindex)\r\n",
        "        freqs[maxindex] += 1\r\n",
        "        maxavg = np.max(freqs)\r\n",
        "        maxavgindex = np.where(freqs == maxavg)[0][0]\r\n",
        "\r\n",
        "        # Every 5 samples, add the avg max to a rolling average\r\n",
        "        if sample % 10 == 0:\r\n",
        "            if len(longterm_rolling_average) >= LONGTERM_ROLLING_AVERAGE_SAMPLES:\r\n",
        "                oldest = longterm_rolling_average.pop(0)\r\n",
        "                longterm_freqs[oldest] -= 1\r\n",
        "            longterm_rolling_average.append(maxavgindex)\r\n",
        "            longterm_freqs[maxavgindex] += 1\r\n",
        "            maxmood = np.where(longterm_freqs == np.max(longterm_freqs))[0][0]\r\n",
        "\r\n",
        "            if prevmaxmood is None or prevmaxmood != maxmood:\r\n",
        "                if maxmood == 1:\r\n",
        "                    maxmood = prevmaxmood\r\n",
        "                elif maxmood in [2, 4]:\r\n",
        "                    continue\r\n",
        "                prevmaxmood = maxmood\r\n",
        "                next_track(spotify, spotipy_dict[maxmood])\r\n",
        "\r\n",
        "        sample += 1\r\n",
        "\r\n",
        "        cv2.putText(frame, emotion_dict[maxavgindex], (x + 20, y - 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2,\r\n",
        "                    cv2.LINE_AA)\r\n",
        "        cv2.putText(frame, action_dict[maxavgindex], (x + 20, y - 60), cv2.FONT_ITALIC, 1, (0, 255, 0), 2,\r\n",
        "                    cv2.LINE_AA)\r\n",
        "        cv2.putText(frame, emotion_dict[maxmood], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\r\n",
        "\r\n",
        "    # Show frame to user\r\n",
        "    cv2.imshow(\"Frame: Pres 'q' to exit the program\", frame)\r\n",
        "    key = cv2.waitKey(1) & 0xFF\r\n",
        "\r\n",
        "    # Quit program by pressing 'q'\r\n",
        "    if key == ord(\"q\"):\r\n",
        "        spotify.pause_playback()\r\n",
        "        break\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltc1NrQmyemT"
      },
      "source": [
        "\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVzFgZvNye73"
      },
      "source": [
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\r\n",
        "\r\n",
        "model_info = model.fit(\r\n",
        "    train_generator,\r\n",
        "    steps_per_epoch=num_train // batch_size,\r\n",
        "    epochs=num_epoch,\r\n",
        "    validation_data=validation_generator,\r\n",
        "    validation_steps=num_val // batch_size)\r\n",
        "\r\n",
        "plot_model_history(model_info)\r\n",
        "model.save_weights('model_testing.h5')\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}